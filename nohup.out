Using cache found in /home/harsh/.cache/torch/hub/pytorch_vision_main
Replaced layer 'fc' with new classification head (11 classes).

Model Summary: ResNet
--------------------------------------------------------------------------------
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| Layer Name            | Layer Type        |   Parameters | Input Shape                 | Output Shape                |
+=======================+===================+==============+=============================+=============================+
| conv1                 | Conv2d            |         9408 | torch.Size([1, 3, 64, 64])  | torch.Size([1, 64, 32, 32]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| bn1                   | BatchNorm2d       |          128 | torch.Size([1, 64, 32, 32]) | torch.Size([1, 64, 32, 32]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| relu                  | ReLU              |            0 | torch.Size([1, 64, 32, 32]) | torch.Size([1, 64, 32, 32]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| maxpool               | MaxPool2d         |            0 | torch.Size([1, 64, 32, 32]) | torch.Size([1, 64, 16, 16]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer1                | Sequential        |       147968 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 64, 16, 16]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer1.0              | BasicBlock        |        73984 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 64, 16, 16]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer1.0.conv1        | Conv2d            |        36864 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 64, 16, 16]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer1.0.bn1          | BatchNorm2d       |          128 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 64, 16, 16]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer1.0.relu         | ReLU              |            0 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 64, 16, 16]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer1.0.conv2        | Conv2d            |        36864 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 64, 16, 16]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer1.0.bn2          | BatchNorm2d       |          128 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 64, 16, 16]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer1.1              | BasicBlock        |        73984 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 64, 16, 16]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer1.1.conv1        | Conv2d            |        36864 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 64, 16, 16]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer1.1.bn1          | BatchNorm2d       |          128 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 64, 16, 16]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer1.1.relu         | ReLU              |            0 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 64, 16, 16]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer1.1.conv2        | Conv2d            |        36864 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 64, 16, 16]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer1.1.bn2          | BatchNorm2d       |          128 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 64, 16, 16]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2                | Sequential        |       525568 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2.0              | BasicBlock        |       230144 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2.0.conv1        | Conv2d            |        73728 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2.0.bn1          | BatchNorm2d       |          256 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2.0.relu         | ReLU              |            0 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2.0.conv2        | Conv2d            |       147456 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2.0.bn2          | BatchNorm2d       |          256 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2.0.downsample   | Sequential        |         8448 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2.0.downsample.0 | Conv2d            |         8192 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2.0.downsample.1 | BatchNorm2d       |          256 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2.1              | BasicBlock        |       295424 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2.1.conv1        | Conv2d            |       147456 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2.1.bn1          | BatchNorm2d       |          256 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2.1.relu         | ReLU              |            0 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2.1.conv2        | Conv2d            |       147456 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2.1.bn2          | BatchNorm2d       |          256 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3                | Sequential        |      2099712 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3.0              | BasicBlock        |       919040 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3.0.conv1        | Conv2d            |       294912 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3.0.bn1          | BatchNorm2d       |          512 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3.0.relu         | ReLU              |            0 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3.0.conv2        | Conv2d            |       589824 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3.0.bn2          | BatchNorm2d       |          512 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3.0.downsample   | Sequential        |        33280 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3.0.downsample.0 | Conv2d            |        32768 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3.0.downsample.1 | BatchNorm2d       |          512 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3.1              | BasicBlock        |      1180672 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3.1.conv1        | Conv2d            |       589824 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3.1.bn1          | BatchNorm2d       |          512 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3.1.relu         | ReLU              |            0 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3.1.conv2        | Conv2d            |       589824 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3.1.bn2          | BatchNorm2d       |          512 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4                | Sequential        |      8393728 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4.0              | BasicBlock        |      3673088 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4.0.conv1        | Conv2d            |      1179648 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4.0.bn1          | BatchNorm2d       |         1024 | torch.Size([1, 512, 2, 2])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4.0.relu         | ReLU              |            0 | torch.Size([1, 512, 2, 2])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4.0.conv2        | Conv2d            |      2359296 | torch.Size([1, 512, 2, 2])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4.0.bn2          | BatchNorm2d       |         1024 | torch.Size([1, 512, 2, 2])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4.0.downsample   | Sequential        |       132096 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4.0.downsample.0 | Conv2d            |       131072 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4.0.downsample.1 | BatchNorm2d       |         1024 | torch.Size([1, 512, 2, 2])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4.1              | BasicBlock        |      4720640 | torch.Size([1, 512, 2, 2])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4.1.conv1        | Conv2d            |      2359296 | torch.Size([1, 512, 2, 2])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4.1.bn1          | BatchNorm2d       |         1024 | torch.Size([1, 512, 2, 2])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4.1.relu         | ReLU              |            0 | torch.Size([1, 512, 2, 2])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4.1.conv2        | Conv2d            |      2359296 | torch.Size([1, 512, 2, 2])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4.1.bn2          | BatchNorm2d       |         1024 | torch.Size([1, 512, 2, 2])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| avgpool               | AdaptiveAvgPool2d |            0 | torch.Size([1, 512, 2, 2])  | torch.Size([1, 512, 1, 1])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| fc                    | Linear            |         5643 | torch.Size([1, 512])        | torch.Size([1, 11])         |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
Using cache found in /home/harsh/.cache/torch/hub/pytorch_vision_main

--------------------------------------------------------------------------------
Total Trainable Parameters: 33,689,931
--------------------------------------------------------------------------------
total params:  33689931
Replaced layer 'fc' with new classification head (11 classes).

Model Summary: ResNet
--------------------------------------------------------------------------------
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| Layer Name            | Layer Type        |   Parameters | Input Shape                 | Output Shape                |
+=======================+===================+==============+=============================+=============================+
| conv1                 | Conv2d            |         9408 | torch.Size([1, 3, 64, 64])  | torch.Size([1, 64, 32, 32]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| bn1                   | BatchNorm2d       |          128 | torch.Size([1, 64, 32, 32]) | torch.Size([1, 64, 32, 32]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| relu                  | ReLU              |            0 | torch.Size([1, 64, 32, 32]) | torch.Size([1, 64, 32, 32]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| maxpool               | MaxPool2d         |            0 | torch.Size([1, 64, 32, 32]) | torch.Size([1, 64, 16, 16]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer1                | Sequential        |       147968 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 64, 16, 16]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer1.0              | BasicBlock        |        73984 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 64, 16, 16]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer1.0.conv1        | Conv2d            |        36864 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 64, 16, 16]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer1.0.bn1          | BatchNorm2d       |          128 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 64, 16, 16]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer1.0.relu         | ReLU              |            0 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 64, 16, 16]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer1.0.conv2        | Conv2d            |        36864 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 64, 16, 16]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer1.0.bn2          | BatchNorm2d       |          128 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 64, 16, 16]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer1.1              | BasicBlock        |        73984 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 64, 16, 16]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer1.1.conv1        | Conv2d            |        36864 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 64, 16, 16]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer1.1.bn1          | BatchNorm2d       |          128 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 64, 16, 16]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer1.1.relu         | ReLU              |            0 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 64, 16, 16]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer1.1.conv2        | Conv2d            |        36864 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 64, 16, 16]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer1.1.bn2          | BatchNorm2d       |          128 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 64, 16, 16]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2                | Sequential        |       525568 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2.0              | BasicBlock        |       230144 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2.0.conv1        | Conv2d            |        73728 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2.0.bn1          | BatchNorm2d       |          256 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2.0.relu         | ReLU              |            0 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2.0.conv2        | Conv2d            |       147456 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2.0.bn2          | BatchNorm2d       |          256 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2.0.downsample   | Sequential        |         8448 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2.0.downsample.0 | Conv2d            |         8192 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2.0.downsample.1 | BatchNorm2d       |          256 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2.1              | BasicBlock        |       295424 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2.1.conv1        | Conv2d            |       147456 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2.1.bn1          | BatchNorm2d       |          256 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2.1.relu         | ReLU              |            0 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2.1.conv2        | Conv2d            |       147456 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2.1.bn2          | BatchNorm2d       |          256 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3                | Sequential        |      2099712 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3.0              | BasicBlock        |       919040 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3.0.conv1        | Conv2d            |       294912 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3.0.bn1          | BatchNorm2d       |          512 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3.0.relu         | ReLU              |            0 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3.0.conv2        | Conv2d            |       589824 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3.0.bn2          | BatchNorm2d       |          512 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3.0.downsample   | Sequential        |        33280 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3.0.downsample.0 | Conv2d            |        32768 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3.0.downsample.1 | BatchNorm2d       |          512 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3.1              | BasicBlock        |      1180672 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3.1.conv1        | Conv2d            |       589824 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3.1.bn1          | BatchNorm2d       |          512 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3.1.relu         | ReLU              |            0 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3.1.conv2        | Conv2d            |       589824 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3.1.bn2          | BatchNorm2d       |          512 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4                | Sequential        |      8393728 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4.0              | BasicBlock        |      3673088 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4.0.conv1        | Conv2d            |      1179648 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4.0.bn1          | BatchNorm2d       |         1024 | torch.Size([1, 512, 2, 2])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4.0.relu         | ReLU              |            0 | torch.Size([1, 512, 2, 2])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4.0.conv2        | Conv2d            |      2359296 | torch.Size([1, 512, 2, 2])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4.0.bn2          | BatchNorm2d       |         1024 | torch.Size([1, 512, 2, 2])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4.0.downsample   | Sequential        |       132096 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4.0.downsample.0 | Conv2d            |       131072 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4.0.downsample.1 | BatchNorm2d       |         1024 | torch.Size([1, 512, 2, 2])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4.1              | BasicBlock        |      4720640 | torch.Size([1, 512, 2, 2])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4.1.conv1        | Conv2d            |      2359296 | torch.Size([1, 512, 2, 2])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4.1.bn1          | BatchNorm2d       |         1024 | torch.Size([1, 512, 2, 2])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4.1.relu         | ReLU              |            0 | torch.Size([1, 512, 2, 2])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4.1.conv2        | Conv2d            |      2359296 | torch.Size([1, 512, 2, 2])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4.1.bn2          | BatchNorm2d       |         1024 | torch.Size([1, 512, 2, 2])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| avgpool               | AdaptiveAvgPool2d |            0 | torch.Size([1, 512, 2, 2])  | torch.Size([1, 512, 1, 1])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| fc                    | Linear            |         5643 | torch.Size([1, 512])        | torch.Size([1, 11])         |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+Using cache found in /home/harsh/.cache/torch/hub/pytorch_vision_main

--------------------------------------------------------------------------------
Total Trainable Parameters: 33,689,931
--------------------------------------------------------------------------------
total params:  33689931
Replaced layer 'fc' with new classification head (11 classes).

Model Summary: ResNet
--------------------------------------------------------------------------------
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| Layer Name            | Layer Type        |   Parameters | Input Shape                 | Output Shape                |
+=======================+===================+==============+=============================+=============================+
| conv1                 | Conv2d            |         9408 | torch.Size([1, 3, 64, 64])  | torch.Size([1, 64, 32, 32]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| bn1                   | BatchNorm2d       |          128 | torch.Size([1, 64, 32, 32]) | torch.Size([1, 64, 32, 32]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| relu                  | ReLU              |            0 | torch.Size([1, 64, 32, 32]) | torch.Size([1, 64, 32, 32]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| maxpool               | MaxPool2d         |            0 | torch.Size([1, 64, 32, 32]) | torch.Size([1, 64, 16, 16]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer1                | Sequential        |       147968 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 64, 16, 16]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer1.0              | BasicBlock        |        73984 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 64, 16, 16]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer1.0.conv1        | Conv2d            |        36864 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 64, 16, 16]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer1.0.bn1          | BatchNorm2d       |          128 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 64, 16, 16]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer1.0.relu         | ReLU              |            0 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 64, 16, 16]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer1.0.conv2        | Conv2d            |        36864 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 64, 16, 16]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer1.0.bn2          | BatchNorm2d       |          128 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 64, 16, 16]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer1.1              | BasicBlock        |        73984 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 64, 16, 16]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer1.1.conv1        | Conv2d            |        36864 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 64, 16, 16]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer1.1.bn1          | BatchNorm2d       |          128 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 64, 16, 16]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer1.1.relu         | ReLU              |            0 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 64, 16, 16]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer1.1.conv2        | Conv2d            |        36864 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 64, 16, 16]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer1.1.bn2          | BatchNorm2d       |          128 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 64, 16, 16]) |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2                | Sequential        |       525568 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2.0              | BasicBlock        |       230144 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2.0.conv1        | Conv2d            |        73728 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2.0.bn1          | BatchNorm2d       |          256 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2.0.relu         | ReLU              |            0 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2.0.conv2        | Conv2d            |       147456 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2.0.bn2          | BatchNorm2d       |          256 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2.0.downsample   | Sequential        |         8448 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2.0.downsample.0 | Conv2d            |         8192 | torch.Size([1, 64, 16, 16]) | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2.0.downsample.1 | BatchNorm2d       |          256 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2.1              | BasicBlock        |       295424 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2.1.conv1        | Conv2d            |       147456 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2.1.bn1          | BatchNorm2d       |          256 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2.1.relu         | ReLU              |            0 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2.1.conv2        | Conv2d            |       147456 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer2.1.bn2          | BatchNorm2d       |          256 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 128, 8, 8])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3                | Sequential        |      2099712 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3.0              | BasicBlock        |       919040 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3.0.conv1        | Conv2d            |       294912 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3.0.bn1          | BatchNorm2d       |          512 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3.0.relu         | ReLU              |            0 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3.0.conv2        | Conv2d            |       589824 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3.0.bn2          | BatchNorm2d       |          512 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3.0.downsample   | Sequential        |        33280 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3.0.downsample.0 | Conv2d            |        32768 | torch.Size([1, 128, 8, 8])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3.0.downsample.1 | BatchNorm2d       |          512 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3.1              | BasicBlock        |      1180672 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3.1.conv1        | Conv2d            |       589824 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3.1.bn1          | BatchNorm2d       |          512 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3.1.relu         | ReLU              |            0 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3.1.conv2        | Conv2d            |       589824 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer3.1.bn2          | BatchNorm2d       |          512 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 256, 4, 4])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4                | Sequential        |      8393728 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4.0              | BasicBlock        |      3673088 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4.0.conv1        | Conv2d            |      1179648 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4.0.bn1          | BatchNorm2d       |         1024 | torch.Size([1, 512, 2, 2])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4.0.relu         | ReLU              |            0 | torch.Size([1, 512, 2, 2])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4.0.conv2        | Conv2d            |      2359296 | torch.Size([1, 512, 2, 2])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4.0.bn2          | BatchNorm2d       |         1024 | torch.Size([1, 512, 2, 2])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4.0.downsample   | Sequential        |       132096 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4.0.downsample.0 | Conv2d            |       131072 | torch.Size([1, 256, 4, 4])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4.0.downsample.1 | BatchNorm2d       |         1024 | torch.Size([1, 512, 2, 2])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4.1              | BasicBlock        |      4720640 | torch.Size([1, 512, 2, 2])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4.1.conv1        | Conv2d            |      2359296 | torch.Size([1, 512, 2, 2])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4.1.bn1          | BatchNorm2d       |         1024 | torch.Size([1, 512, 2, 2])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4.1.relu         | ReLU              |            0 | torch.Size([1, 512, 2, 2])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4.1.conv2        | Conv2d            |      2359296 | torch.Size([1, 512, 2, 2])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| layer4.1.bn2          | BatchNorm2d       |         1024 | torch.Size([1, 512, 2, 2])  | torch.Size([1, 512, 2, 2])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| avgpool               | AdaptiveAvgPool2d |            0 | torch.Size([1, 512, 2, 2])  | torch.Size([1, 512, 1, 1])  |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
| fc                    | Linear            |         5643 | torch.Size([1, 512])        | torch.Size([1, 11])         |
+-----------------------+-------------------+--------------+-----------------------------+-----------------------------+
--------------------------------------------------------------------------------
Total Trainable Parameters: 33,689,931
--------------------------------------------------------------------------------
total params:  33689931

Training:   0%|          | 0/271 [00:00<?, ?it/s]
Training:   0%|          | 1/271 [00:00<00:49,  5.51it/s]
Training:   3%|         | 9/271 [00:00<00:07, 36.54it/s]
Training:   6%|         | 17/271 [00:00<00:04, 51.24it/s]
Training:   9%|         | 25/271 [00:00<00:04, 59.50it/s]
Training:  12%|        | 33/271 [00:00<00:03, 64.49it/s]
Training:  15%|        | 41/271 [00:00<00:03, 67.50it/s]
Training:  18%|        | 49/271 [00:00<00:03, 69.60it/s]
Training:  21%|        | 57/271 [00:00<00:03, 70.96it/s]
Training:  24%|       | 65/271 [00:01<00:02, 71.89it/s]
Training:  27%|       | 73/271 [00:01<00:02, 72.51it/s]
Training:  30%|       | 81/271 [00:01<00:02, 73.00it/s]
Training:  33%|      | 89/271 [00:01<00:02, 73.27it/s]
Training:  36%|      | 97/271 [00:01<00:02, 73.57it/s]
Training:  39%|      | 105/271 [00:01<00:02, 73.77it/s]
Training:  42%|     | 113/271 [00:01<00:02, 73.88it/s]
Training:  45%|     | 121/271 [00:01<00:02, 73.66it/s]
Training:  48%|     | 129/271 [00:01<00:01, 73.82it/s]
Training:  51%|     | 137/271 [00:02<00:01, 73.97it/s]
Training:  54%|    | 145/271 [00:02<00:01, 74.07it/s]
Training:  56%|    | 153/271 [00:02<00:01, 74.02it/s]
Training:  59%|    | 161/271 [00:02<00:01, 73.98it/s]
Training:  62%|   | 169/271 [00:02<00:01, 73.94it/s]
Training:  65%|   | 177/271 [00:02<00:01, 73.98it/s]
Training:  68%|   | 185/271 [00:02<00:01, 74.06it/s]
Training:  71%|   | 193/271 [00:02<00:01, 73.87it/s]
Training:  74%|  | 201/271 [00:02<00:00, 73.93it/s]
Training:  77%|  | 209/271 [00:02<00:00, 73.99it/s]
Training:  80%|  | 217/271 [00:03<00:00, 74.08it/s]
Training:  83%| | 225/271 [00:03<00:00, 74.10it/s]
Training:  86%| | 233/271 [00:03<00:00, 74.16it/s]
Training:  89%| | 241/271 [00:03<00:00, 74.14it/s]
Training:  92%|| 249/271 [00:03<00:00, 74.19it/s]
Training:  95%|| 257/271 [00:03<00:00, 74.19it/s]
Training:  98%|| 265/271 [00:03<00:00, 73.86it/s]
Training: 100%|| 271/271 [00:03<00:00, 70.17it/s]
/home/harsh/Lab_Work/Bhaang/bhaang/Medical_imaging/logger.py:63: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  self.df = pd.concat([self.df, row_df], ignore_index=True)

Training:   0%|          | 0/271 [00:00<?, ?it/s]
Training:   3%|         | 7/271 [00:00<00:03, 68.24it/s]
Training:   6%|         | 15/271 [00:00<00:03, 72.06it/s]
Training:   8%|         | 23/271 [00:00<00:03, 73.09it/s]
Training:  11%|        | 31/271 [00:00<00:03, 73.71it/s]
Training:  14%|        | 39/271 [00:00<00:03, 74.02it/s]
Training:  17%|        | 47/271 [00:00<00:03, 73.66it/s]
Training:  20%|        | 55/271 [00:00<00:02, 73.89it/s]
Training:  23%|       | 63/271 [00:00<00:02, 74.17it/s]
Training:  26%|       | 71/271 [00:00<00:02, 74.25it/s]
Training:  29%|       | 79/271 [00:01<00:02, 74.42it/s]
Training:  32%|      | 87/271 [00:01<00:02, 74.42it/s]
Training:  35%|      | 95/271 [00:01<00:02, 74.48it/s]
Training:  38%|      | 103/271 [00:01<00:02, 74.07it/s]
Training:  41%|      | 111/271 [00:01<00:02, 74.25it/s]
Training:  44%|     | 119/271 [00:01<00:02, 73.93it/s]
Training:  47%|     | 127/271 [00:01<00:01, 74.08it/s]
Training:  50%|     | 135/271 [00:01<00:01, 74.26it/s]
Training:  53%|    | 143/271 [00:01<00:01, 74.25it/s]
Training:  56%|    | 151/271 [00:02<00:01, 74.25it/s]
Training:  59%|    | 159/271 [00:02<00:01, 74.38it/s]
Training:  62%|   | 167/271 [00:02<00:01, 74.48it/s]
Training:  65%|   | 175/271 [00:02<00:01, 74.49it/s]
Training:  68%|   | 183/271 [00:02<00:01, 74.49it/s]
Training:  70%|   | 191/271 [00:02<00:01, 73.99it/s]
Training:  73%|  | 199/271 [00:02<00:00, 73.14it/s]
Training:  76%|  | 207/271 [00:02<00:00, 73.51it/s]
Training:  79%|  | 215/271 [00:02<00:00, 73.81it/s]
Training:  82%| | 223/271 [00:03<00:00, 73.99it/s]
Training:  85%| | 231/271 [00:03<00:00, 74.11it/s]
Training:  88%| | 239/271 [00:03<00:00, 74.17it/s]
Training:  91%| | 247/271 [00:03<00:00, 74.27it/s]
Training:  94%|| 255/271 [00:03<00:00, 74.30it/s]
Training:  97%|| 263/271 [00:03<00:00, 74.22it/s]
Training: 100%|| 271/271 [00:03<00:00, 74.74it/s]
Training: 100%|| 271/271 [00:03<00:00, 74.08it/s]

Training:   0%|          | 0/271 [00:00<?, ?it/s]
Training:   2%|         | 6/271 [00:00<00:04, 55.68it/s]
Training:   5%|         | 14/271 [00:00<00:03, 66.16it/s]
Training:   8%|         | 22/271 [00:00<00:03, 69.74it/s]
Training:  11%|         | 30/271 [00:00<00:03, 71.55it/s]
Training:  14%|        | 38/271 [00:00<00:03, 72.28it/s]
Training:  17%|        | 46/271 [00:00<00:03, 72.62it/s]
Training:  20%|        | 54/271 [00:00<00:02, 73.16it/s]
Training:  23%|       | 62/271 [00:00<00:02, 73.45it/s]
Training:  26%|       | 70/271 [00:00<00:02, 73.83it/s]
Training:  29%|       | 78/271 [00:01<00:02, 74.12it/s]
Training:  32%|      | 86/271 [00:01<00:02, 74.38it/s]
Training:  35%|      | 94/271 [00:01<00:02, 74.64it/s]
Training:  38%|      | 102/271 [00:01<00:02, 74.62it/s]
Training:  41%|      | 110/271 [00:01<00:02, 74.57it/s]
Training:  44%|     | 118/271 [00:01<00:02, 74.57it/s]
Training:  46%|     | 126/271 [00:01<00:01, 74.73it/s]
Training:  49%|     | 134/271 [00:01<00:01, 74.83it/s]
Training:  52%|    | 142/271 [00:01<00:01, 74.84it/s]
Training:  55%|    | 150/271 [00:02<00:01, 74.88it/s]
Training:  58%|    | 158/271 [00:02<00:01, 74.95it/s]
Training:  61%|   | 166/271 [00:02<00:01, 74.93it/s]
Training:  64%|   | 174/271 [00:02<00:01, 74.93it/s]
Training:  67%|   | 182/271 [00:02<00:01, 74.95it/s]
Training:  70%|   | 190/271 [00:02<00:01, 74.79it/s]
Training:  73%|  | 198/271 [00:02<00:00, 74.51it/s]
Training:  76%|  | 206/271 [00:02<00:00, 74.44it/s]
Training:  79%|  | 214/271 [00:02<00:00, 74.22it/s]
Training:  82%| | 222/271 [00:03<00:00, 74.21it/s]
Training:  85%| | 230/271 [00:03<00:00, 74.13it/s]
Training:  88%| | 238/271 [00:03<00:00, 74.15it/s]
Training:  91%| | 246/271 [00:03<00:00, 74.17it/s]
Training:  94%|| 254/271 [00:03<00:00, 74.18it/s]
Training:  97%|| 262/271 [00:03<00:00, 74.21it/s]
Training: 100%|| 270/271 [00:03<00:00, 74.16it/s]
Training: 100%|| 271/271 [00:03<00:00, 74.03it/s]

Training:   0%|          | 0/271 [00:00<?, ?it/s]
Training:   3%|         | 8/271 [00:00<00:03, 74.73it/s]
Training:   6%|         | 16/271 [00:00<00:03, 74.70it/s]
Training:   9%|         | 24/271 [00:00<00:03, 74.73it/s]
Training:  12%|        | 32/271 [00:00<00:03, 74.89it/s]
Training:  15%|        | 40/271 [00:00<00:03, 74.97it/s]
Training:  18%|        | 48/271 [00:00<00:02, 74.95it/s]
Training:  21%|        | 56/271 [00:00<00:02, 75.02it/s]
Training:  24%|       | 64/271 [00:00<00:02, 74.99it/s]
Training:  27%|       | 72/271 [00:00<00:02, 75.00it/s]
Training:  30%|       | 80/271 [00:01<00:02, 75.04it/s]
Training:  32%|      | 88/271 [00:01<00:02, 75.00it/s]
Training:  35%|      | 96/271 [00:01<00:02, 75.01it/s]
Training:  38%|      | 104/271 [00:01<00:02, 75.08it/s]
Training:  41%|     | 112/271 [00:01<00:02, 75.14it/s]
Training:  44%|     | 120/271 [00:01<00:02, 75.06it/s]
Training:  47%|     | 128/271 [00:01<00:01, 74.81it/s]
Training:  50%|     | 136/271 [00:01<00:01, 74.64it/s]
Training:  53%|    | 144/271 [00:01<00:01, 74.62it/s]
Training:  56%|    | 152/271 [00:02<00:01, 74.60it/s]
Training:  59%|    | 160/271 [00:02<00:01, 74.70it/s]
Training:  62%|   | 168/271 [00:02<00:01, 74.69it/s]
Training:  65%|   | 176/271 [00:02<00:01, 74.77it/s]
Training:  68%|   | 184/271 [00:02<00:01, 74.68it/s]
Training:  71%|   | 192/271 [00:02<00:01, 74.46it/s]
Training:  74%|  | 200/271 [00:02<00:00, 74.20it/s]
Training:  77%|  | 208/271 [00:02<00:00, 74.26it/s]
Training:  80%|  | 216/271 [00:02<00:00, 74.35it/s]
Training:  83%| | 224/271 [00:02<00:00, 74.38it/s]
Training:  86%| | 232/271 [00:03<00:00, 74.55it/s]
Training:  89%| | 240/271 [00:03<00:00, 74.53it/s]
Training:  92%|| 248/271 [00:03<00:00, 74.33it/s]
Training:  94%|| 256/271 [00:03<00:00, 74.38it/s]
Training:  97%|| 264/271 [00:03<00:00, 74.50it/s]
Training: 100%|| 271/271 [00:03<00:00, 74.85it/s]

Training:   0%|          | 0/271 [00:00<?, ?it/s]
Training:   3%|         | 7/271 [00:00<00:03, 68.93it/s]
Training:   6%|         | 15/271 [00:00<00:03, 72.13it/s]
Training:   8%|         | 23/271 [00:00<00:03, 72.87it/s]
Training:  11%|        | 31/271 [00:00<00:03, 73.43it/s]
Training:  14%|        | 39/271 [00:00<00:03, 73.85it/s]
Training:  17%|        | 47/271 [00:00<00:03, 73.95it/s]
Training:  20%|        | 55/271 [00:00<00:02, 73.68it/s]
Training:  23%|       | 63/271 [00:00<00:02, 73.75it/s]
Training:  26%|       | 71/271 [00:00<00:02, 73.82it/s]
Training:  29%|       | 79/271 [00:01<00:02, 73.95it/s]
Training:  32%|      | 87/271 [00:01<00:02, 74.03it/s]
Training:  35%|      | 95/271 [00:01<00:02, 73.71it/s]
Training:  38%|      | 103/271 [00:01<00:02, 73.63it/s]
Training:  41%|      | 111/271 [00:01<00:02, 73.72it/s]
Training:  44%|     | 119/271 [00:01<00:02, 73.87it/s]
Training:  47%|     | 127/271 [00:01<00:01, 73.15it/s]
Training:  50%|     | 135/271 [00:01<00:01, 71.91it/s]
Training:  53%|    | 143/271 [00:01<00:01, 72.33it/s]
Training:  56%|    | 151/271 [00:02<00:01, 72.80it/s]
Training:  59%|    | 159/271 [00:02<00:01, 73.39it/s]
Training:  62%|   | 167/271 [00:02<00:01, 73.45it/s]
Training:  65%|   | 175/271 [00:02<00:01, 73.73it/s]
Training:  68%|   | 183/271 [00:02<00:01, 73.50it/s]
Training:  70%|   | 191/271 [00:02<00:01, 73.42it/s]
Training:  73%|  | 199/271 [00:02<00:00, 73.29it/s]
Training:  76%|  | 207/271 [00:02<00:00, 73.55it/s]
Training:  79%|  | 215/271 [00:02<00:00, 73.87it/s]
Training:  82%| | 223/271 [00:03<00:00, 74.39it/s]
Training:  85%| | 231/271 [00:03<00:00, 75.07it/s]
Training:  88%| | 239/271 [00:03<00:00, 75.63it/s]
Training:  91%| | 247/271 [00:03<00:00, 76.03it/s]
Training:  94%|| 255/271 [00:03<00:00, 76.16it/s]
Training:  97%|| 263/271 [00:03<00:00, 76.33it/s]
Training: 100%|| 271/271 [00:03<00:00, 74.20it/s]

Training:   0%|          | 0/271 [00:00<?, ?it/s]
Training:   3%|         | 8/271 [00:00<00:03, 75.96it/s]
Training:   6%|         | 16/271 [00:00<00:03, 76.20it/s]
Training:   9%|         | 24/271 [00:00<00:03, 76.42it/s]
Training:  12%|        | 32/271 [00:00<00:03, 76.30it/s]
Training:  15%|        | 40/271 [00:00<00:03, 76.33it/s]
Training:  18%|        | 48/271 [00:00<00:02, 76.49it/s]
Training:  21%|        | 56/271 [00:00<00:02, 76.59it/s]
Training:  24%|       | 64/271 [00:00<00:02, 76.64it/s]
Training:  27%|       | 72/271 [00:00<00:02, 76.46it/s]
Training:  30%|       | 80/271 [00:01<00:02, 75.60it/s]
Training:  32%|      | 88/271 [00:01<00:02, 75.09it/s]
Training:  35%|      | 96/271 [00:01<00:02, 74.68it/s]
Training:  38%|      | 104/271 [00:01<00:02, 74.11it/s]
Training:  41%|     | 112/271 [00:01<00:02, 74.09it/s]
Training:  44%|     | 120/271 [00:01<00:02, 73.97it/s]
Training:  47%|     | 128/271 [00:01<00:01, 73.97it/s]
Training:  50%|     | 136/271 [00:01<00:01, 73.50it/s]
Training:  53%|    | 144/271 [00:01<00:01, 73.60it/s]
Training:  56%|    | 152/271 [00:02<00:01, 73.66it/s]
Training:  59%|    | 160/271 [00:02<00:01, 73.60it/s]
Training:  62%|   | 168/271 [00:02<00:01, 73.62it/s]
Training:  65%|   | 176/271 [00:02<00:01, 73.51it/s]
Training:  68%|   | 184/271 [00:02<00:01, 73.58it/s]
Training:  71%|   | 192/271 [00:02<00:01, 73.44it/s]
Training:  74%|  | 200/271 [00:02<00:00, 73.59it/s]
Training:  77%|  | 208/271 [00:02<00:00, 73.42it/s]
Training:  80%|  | 216/271 [00:02<00:00, 73.73it/s]
Training:  83%| | 224/271 [00:03<00:00, 73.76it/s]
Training:  86%| | 232/271 [00:03<00:00, 73.81it/s]
Training:  89%| | 240/271 [00:03<00:00, 73.88it/s]
Training:  92%|| 248/271 [00:03<00:00, 73.87it/s]
Training:  94%|| 256/271 [00:03<00:00, 73.89it/s]
Training:  97%|| 264/271 [00:03<00:00, 74.10it/s]
Training: 100%|| 271/271 [00:03<00:00, 74.59it/s]

Training:   0%|          | 0/271 [00:00<?, ?it/s]
Training:   3%|         | 8/271 [00:00<00:03, 72.78it/s]
Training:   6%|         | 16/271 [00:00<00:03, 71.42it/s]
Training:   9%|         | 24/271 [00:00<00:03, 72.46it/s]
Training:  12%|        | 32/271 [00:00<00:03, 73.05it/s]
Training:  15%|        | 40/271 [00:00<00:03, 73.35it/s]
Training:  18%|        | 48/271 [00:00<00:03, 73.72it/s]
Training:  21%|        | 56/271 [00:00<00:02, 74.06it/s]
Training:  24%|       | 64/271 [00:00<00:02, 73.96it/s]
Training:  27%|       | 72/271 [00:00<00:02, 74.17it/s]
Training:  30%|       | 80/271 [00:01<00:02, 74.36it/s]
Training:  32%|      | 88/271 [00:01<00:02, 74.49it/s]
Training:  35%|      | 96/271 [00:01<00:02, 74.59it/s]
Training:  38%|      | 104/271 [00:01<00:02, 74.64it/s]
Training:  41%|     | 112/271 [00:01<00:02, 74.72it/s]
Training:  44%|     | 120/271 [00:01<00:02, 74.76it/s]
Training:  47%|     | 128/271 [00:01<00:01, 74.74it/s]
Training:  50%|     | 136/271 [00:01<00:01, 74.57it/s]
Training:  53%|    | 144/271 [00:01<00:01, 74.63it/s]
Training:  56%|    | 152/271 [00:02<00:01, 74.69it/s]
Training:  59%|    | 160/271 [00:02<00:01, 74.71it/s]
Training:  62%|   | 168/271 [00:02<00:01, 74.77it/s]
Training:  65%|   | 176/271 [00:02<00:01, 74.74it/s]
Training:  68%|   | 184/271 [00:02<00:01, 74.79it/s]
Training:  71%|   | 192/271 [00:02<00:01, 74.78it/s]
Training:  74%|  | 200/271 [00:02<00:00, 74.71it/s]
Training:  77%|  | 208/271 [00:02<00:00, 74.72it/s]
Training:  80%|  | 216/271 [00:02<00:00, 74.55it/s]
Training:  83%| | 224/271 [00:03<00:00, 74.59it/s]
Training:  86%| | 232/271 [00:03<00:00, 74.57it/s]
Training:  89%| | 240/271 [00:03<00:00, 74.64it/s]
Training:  92%|| 248/271 [00:03<00:00, 74.53it/s]
Training:  94%|| 256/271 [00:03<00:00, 74.36it/s]
Training:  97%|| 264/271 [00:03<00:00, 74.16it/s]
Training: 100%|| 271/271 [00:03<00:00, 74.49it/s]

Training:   0%|          | 0/271 [00:00<?, ?it/s]
Training:   3%|         | 8/271 [00:00<00:03, 71.03it/s]
Training:   6%|         | 16/271 [00:00<00:03, 72.95it/s]
Training:   9%|         | 24/271 [00:00<00:03, 73.61it/s]
Training:  12%|        | 32/271 [00:00<00:03, 74.10it/s]
Training:  15%|        | 40/271 [00:00<00:03, 74.30it/s]
Training:  18%|        | 48/271 [00:00<00:02, 74.40it/s]
Training:  21%|        | 56/271 [00:00<00:02, 74.28it/s]
Training:  24%|       | 64/271 [00:00<00:02, 74.29it/s]
Training:  27%|       | 72/271 [00:00<00:02, 74.15it/s]
Training:  30%|       | 80/271 [00:01<00:02, 74.20it/s]
Training:  32%|      | 88/271 [00:01<00:02, 74.16it/s]
Training:  35%|      | 96/271 [00:01<00:02, 74.23it/s]
Training:  38%|      | 104/271 [00:01<00:02, 74.20it/s]
Training:  41%|     | 112/271 [00:01<00:02, 74.08it/s]
Training:  44%|     | 120/271 [00:01<00:02, 74.11it/s]
Training:  47%|     | 128/271 [00:01<00:01, 74.24it/s]
Training:  50%|     | 136/271 [00:01<00:01, 74.26it/s]
Training:  53%|    | 144/271 [00:01<00:01, 74.06it/s]
Training:  56%|    | 152/271 [00:02<00:01, 74.22it/s]
Training:  59%|    | 160/271 [00:02<00:01, 74.32it/s]
Training:  62%|   | 168/271 [00:02<00:01, 74.40it/s]
Training:  65%|   | 176/271 [00:02<00:01, 74.35it/s]
Training:  68%|   | 184/271 [00:02<00:01, 74.43it/s]
Training:  71%|   | 192/271 [00:02<00:01, 74.48it/s]
Training:  74%|  | 200/271 [00:02<00:00, 74.58it/s]
Training:  77%|  | 208/271 [00:02<00:00, 74.54it/s]
Training:  80%|  | 216/271 [00:02<00:00, 74.29it/s]
Training:  83%| | 224/271 [00:03<00:00, 74.32it/s]
Training:  86%| | 232/271 [00:03<00:00, 74.50it/s]
Training:  89%| | 240/271 [00:03<00:00, 74.56it/s]
Training:  92%|| 248/271 [00:03<00:00, 74.63it/s]
Training:  94%|| 256/271 [00:03<00:00, 74.67it/s]
Training:  97%|| 264/271 [00:03<00:00, 74.67it/s]
Training: 100%|| 271/271 [00:03<00:00, 74.47it/s]

Training:   0%|          | 0/271 [00:00<?, ?it/s]
Training:   3%|         | 8/271 [00:00<00:03, 73.76it/s]
Training:   6%|         | 16/271 [00:00<00:03, 74.45it/s]
Training:   9%|         | 24/271 [00:00<00:03, 74.57it/s]
Training:  12%|        | 32/271 [00:00<00:03, 74.72it/s]
Training:  15%|        | 40/271 [00:00<00:03, 74.83it/s]
Training:  18%|        | 48/271 [00:00<00:02, 74.82it/s]
Training:  21%|        | 56/271 [00:00<00:02, 74.84it/s]
Training:  24%|       | 64/271 [00:00<00:02, 74.83it/s]
Training:  27%|       | 72/271 [00:00<00:02, 74.37it/s]
Training:  30%|       | 80/271 [00:01<00:02, 73.73it/s]
Training:  32%|      | 88/271 [00:01<00:02, 73.96it/s]
Training:  35%|      | 96/271 [00:01<00:02, 74.14it/s]
Training:  38%|      | 104/271 [00:01<00:02, 74.37it/s]
Training:  41%|     | 112/271 [00:01<00:02, 74.54it/s]
Training:  44%|     | 120/271 [00:01<00:02, 74.62it/s]
Training:  47%|     | 128/271 [00:01<00:01, 74.65it/s]
Training:  50%|     | 136/271 [00:01<00:01, 74.72it/s]
Training:  53%|    | 144/271 [00:01<00:01, 74.67it/s]
Training:  56%|    | 152/271 [00:02<00:01, 73.85it/s]
Training:  59%|    | 160/271 [00:02<00:01, 73.74it/s]
Training:  62%|   | 168/271 [00:02<00:01, 74.00it/s]
Training:  65%|   | 176/271 [00:02<00:01, 74.28it/s]
Training:  68%|   | 184/271 [00:02<00:01, 74.48it/s]
Training:  71%|   | 192/271 [00:02<00:01, 74.60it/s]
Training:  74%|  | 200/271 [00:02<00:00, 74.67it/s]
Training:  77%|  | 208/271 [00:02<00:00, 74.74it/s]
Training:  80%|  | 216/271 [00:02<00:00, 74.79it/s]
Training:  83%| | 224/271 [00:03<00:00, 74.50it/s]
Training:  86%| | 232/271 [00:03<00:00, 74.44it/s]
Training:  89%| | 240/271 [00:03<00:00, 74.50it/s]
Training:  92%|| 248/271 [00:03<00:00, 74.64it/s]
Training:  94%|| 256/271 [00:03<00:00, 74.71it/s]
Training:  97%|| 264/271 [00:03<00:00, 74.74it/s]
Training: 100%|| 271/271 [00:03<00:00, 74.68it/s]

Training:   0%|          | 0/271 [00:00<?, ?it/s]
Training:   3%|         | 8/271 [00:00<00:03, 73.61it/s]
Training:   6%|         | 16/271 [00:00<00:03, 74.03it/s]
Training:   9%|         | 24/271 [00:00<00:03, 74.33it/s]
Training:  12%|        | 32/271 [00:00<00:03, 74.54it/s]
Training:  15%|        | 40/271 [00:00<00:03, 74.66it/s]
Training:  18%|        | 48/271 [00:00<00:02, 74.57it/s]
Training:  21%|        | 56/271 [00:00<00:02, 74.63it/s]
Training:  24%|       | 64/271 [00:00<00:02, 74.60it/s]
Training:  27%|       | 72/271 [00:00<00:02, 74.63it/s]
Training:  30%|       | 80/271 [00:01<00:02, 74.38it/s]
Training:  32%|      | 88/271 [00:01<00:02, 74.53it/s]
Training:  35%|      | 96/271 [00:01<00:02, 74.65it/s]
Training:  38%|      | 104/271 [00:01<00:02, 74.57it/s]
Training:  41%|     | 112/271 [00:01<00:02, 74.55it/s]
Training:  44%|     | 120/271 [00:01<00:02, 74.63it/s]
Training:  47%|     | 128/271 [00:01<00:01, 74.66it/s]
Training:  50%|     | 136/271 [00:01<00:01, 74.65it/s]
Training:  53%|    | 144/271 [00:01<00:01, 74.63it/s]
Training:  56%|    | 152/271 [00:02<00:01, 74.35it/s]
Training:  59%|    | 160/271 [00:02<00:01, 73.90it/s]
Training:  62%|   | 168/271 [00:02<00:01, 73.40it/s]
Training:  65%|   | 176/271 [00:02<00:01, 73.27it/s]
Training:  68%|   | 184/271 [00:02<00:01, 73.69it/s]
Training:  71%|   | 192/271 [00:02<00:01, 74.02it/s]
Training:  74%|  | 200/271 [00:02<00:00, 74.12it/s]
Training:  77%|  | 208/271 [00:02<00:00, 74.22it/s]
Training:  80%|  | 216/271 [00:02<00:00, 74.13it/s]
Training:  83%| | 224/271 [00:03<00:00, 74.15it/s]
Training:  86%| | 232/271 [00:03<00:00, 74.25it/s]
Training:  89%| | 240/271 [00:03<00:00, 74.33it/s]
Training:  92%|| 248/271 [00:03<00:00, 74.40it/s]
Training:  94%|| 256/271 [00:03<00:00, 74.34it/s]
Training:  97%|| 264/271 [00:03<00:00, 74.40it/s]
Training: 100%|| 271/271 [00:03<00:00, 74.49it/s]

Training:   0%|          | 0/102 [00:00<?, ?it/s]
Training:   8%|         | 8/102 [00:00<00:01, 73.67it/s]
Training:  16%|        | 16/102 [00:00<00:01, 74.11it/s]
Training:  24%|       | 24/102 [00:00<00:01, 74.46it/s]
Training:  31%|      | 32/102 [00:00<00:00, 74.42it/s]
Training:  39%|      | 40/102 [00:00<00:00, 74.49it/s]
Training:  47%|     | 48/102 [00:00<00:00, 74.56it/s]
Training:  55%|    | 56/102 [00:00<00:00, 74.57it/s]
Training:  63%|   | 64/102 [00:00<00:00, 74.53it/s]
Training:  71%|   | 72/102 [00:00<00:00, 74.55it/s]
Training:  78%|  | 80/102 [00:01<00:00, 74.41it/s]
Training:  86%| | 88/102 [00:01<00:00, 74.18it/s]
Training:  94%|| 96/102 [00:01<00:00, 74.33it/s]
Training: 100%|| 102/102 [00:01<00:00, 74.08it/s]

Training:   0%|          | 0/102 [00:00<?, ?it/s]
Training:   8%|         | 8/102 [00:00<00:01, 74.58it/s]
Training:  16%|        | 16/102 [00:00<00:01, 74.47it/s]
Training:  24%|       | 24/102 [00:00<00:01, 74.44it/s]
Training:  31%|      | 32/102 [00:00<00:00, 74.07it/s]
Training:  39%|      | 40/102 [00:00<00:00, 74.29it/s]
Training:  47%|     | 48/102 [00:00<00:00, 74.48it/s]
Training:  55%|    | 56/102 [00:00<00:00, 74.64it/s]
Training:  63%|   | 64/102 [00:00<00:00, 74.75it/s]
Training:  71%|   | 72/102 [00:00<00:00, 74.83it/s]
Training:  78%|  | 80/102 [00:01<00:00, 74.88it/s]
Training:  86%| | 88/102 [00:01<00:00, 74.93it/s]
Training:  94%|| 96/102 [00:01<00:00, 74.90it/s]
Training: 100%|| 102/102 [00:01<00:00, 75.01it/s]

Training:   0%|          | 0/102 [00:00<?, ?it/s]
Training:   8%|         | 8/102 [00:00<00:01, 74.84it/s]
Training:  16%|        | 16/102 [00:00<00:01, 74.87it/s]
Training:  24%|       | 24/102 [00:00<00:01, 74.90it/s]
Training:  31%|      | 32/102 [00:00<00:00, 74.70it/s]
Training:  39%|      | 40/102 [00:00<00:00, 74.83it/s]
Training:  47%|     | 48/102 [00:00<00:00, 74.88it/s]
Training:  55%|    | 56/102 [00:00<00:00, 74.20it/s]
Training:  63%|   | 64/102 [00:00<00:00, 73.80it/s]
Training:  71%|   | 72/102 [00:00<00:00, 73.96it/s]
Training:  78%|  | 80/102 [00:01<00:00, 74.27it/s]
Training:  86%| | 88/102 [00:01<00:00, 73.83it/s]
Training:  94%|| 96/102 [00:01<00:00, 73.95it/s]
Training: 100%|| 102/102 [00:01<00:00, 74.61it/s]

Training:   0%|          | 0/102 [00:00<?, ?it/s]
Training:   8%|         | 8/102 [00:00<00:01, 75.17it/s]
Training:  16%|        | 16/102 [00:00<00:01, 74.88it/s]
Training:  24%|       | 24/102 [00:00<00:01, 74.91it/s]
Training:  31%|      | 32/102 [00:00<00:00, 74.87it/s]
Training:  39%|      | 40/102 [00:00<00:00, 74.86it/s]
Training:  47%|     | 48/102 [00:00<00:00, 74.67it/s]
Training:  55%|    | 56/102 [00:00<00:00, 73.80it/s]
Training:  63%|   | 64/102 [00:00<00:00, 73.41it/s]
Training:  71%|   | 72/102 [00:00<00:00, 73.01it/s]
Training:  78%|  | 80/102 [00:01<00:00, 72.73it/s]
Training:  86%| | 88/102 [00:01<00:00, 73.33it/s]
Training:  89%| | 91/102 [00:01<00:00, 73.05it/s]
Traceback (most recent call last):
  File "/home/harsh/Lab_Work/experiments.py", line 176, in <module>
    "organcmnist": train_model(*models["organcmnist"], train_loader=train_loaders["organcmnist"], val_loader=val_loaders["organcmnist"], source_dataloader_name="organcmnist"),
  File "/home/harsh/Lab_Work/experiments.py", line 167, in train_model
    model = trainer.train()
  File "/home/harsh/Lab_Work/train.py", line 44, in train
    train_loss = self._train_one_epoch()
  File "/home/harsh/Lab_Work/train.py", line 68, in _train_one_epoch
    total_loss += loss.item()
KeyboardInterrupt
